# ğŸ“‚ Raw Data

This folder contains the **original, unmodified datasets** used for the LLM Evaluation Audit.

These files come directly from the [MT-Bench](https://huggingface.co/datasets/lmsys/mt_bench_human_judgments) evaluation pipeline and are used to analyze the credibility of GPT-4 as an evaluator compared to human judgment.

## ğŸ“‘ Files Included
- **human.csv** â€” Human-annotated pairwise model comparisons  
- **gpt4_pair.csv** â€” GPT-4â€“judged pairwise model comparisons  
- **question.jsonl** â€” Metadata including task category for each evaluation

## ğŸ”’ Handling Notes
- **Do not edit** these files directly  
- Only project scripts should reference this folder  
- Any cleaning or preprocessing should be done in the [`data/processed/`](../processed) folder  

## ğŸ§  Purpose
These raw files serve as the foundation for:
- Bias detection  
- Agreement/disagreement analysis  
- Human-validated model performance metrics  

> ğŸ“Œ This folder ensures that the project remains **reproducible** and that the original dataset is always preserved.
